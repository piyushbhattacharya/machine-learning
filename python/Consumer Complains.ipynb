{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datafile_train=r'Data/consumer/Consumer_Complaints_train.csv'\n",
    "datafile_test=r'Data/consumer/Consumer_Complaints_test.csv'\n",
    "cd_train=pd.read_csv(datafile_train)\n",
    "cd_test=pd.read_csv(datafile_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['Date received','Date sent to company']:\n",
    "    cd_train[col]=pd.to_datetime(cd_train[col],infer_datetime_format=True)\n",
    "    cd_test[col]=pd.to_datetime(cd_test[col],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd_train['day_diff']=pd.to_numeric(cd_train['Date sent to company']-cd_train['Date received'])\n",
    "cd_test['day_diff']=pd.to_numeric(cd_test['Date sent to company']-cd_test['Date received'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['Date received','Date sent to company']:\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    cd_test.drop([col],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in cd_train.select_dtypes(['object']).columns:\n",
    "    print(col,':',cd_train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pd.isnull(cd_train['Tags']))\n",
    "len(cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ['Sub-product','Sub-issue','Consumer complaint narrative',\n",
    "            'Company public response','Tags','Consumer consent provided?']:\n",
    "    varname=col.replace('-','_').replace('?','').replace(\" \",'_')+'_isNan'\n",
    "    cd_train[varname]=np.where(pd.isnull(cd_train[col]),1,0)\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    cd_test[varname]=np.where(pd.isnull(cd_test[col]),1,0)\n",
    "    cd_test.drop([col],1,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in cd_train.select_dtypes(['object']).columns:\n",
    "    print(col,':',cd_train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['ZIP code','Company']:\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    cd_test.drop([col],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd_train['Consumer disputed?']=np.where(cd_train['Consumer disputed?']==\"Yes\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=cd_train['Issue'].value_counts()\n",
    "for val in k.axes[0][0:10]:\n",
    "    varname='Issue_'+val.replace(',','_').replace(' ','_')\n",
    "    cd_train[varname]=np.where(cd_train['Issue']==val,1,0)\n",
    "    cd_test[varname]=np.where(cd_test['Issue']==val,1,0)\n",
    "del cd_train['Issue']\n",
    "del cd_test['Issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in cd_train.select_dtypes(['object']).columns:\n",
    "    print(col,':',cd_train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=cd_train['State'].value_counts()\n",
    "for val in k.axes[0][0:15]:\n",
    "    varname='State_'+val.replace(',','_').replace(' ','_')\n",
    "    cd_train[varname]=np.where(cd_train['State']==val,1,0)\n",
    "    cd_test[varname]=np.where(cd_test['State']==val,1,0)\n",
    "del cd_train['State']\n",
    "del cd_test['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ['Product','Submitted via','Company response to consumer','Timely response?']:\n",
    "    \n",
    "    temp=pd.get_dummies(cd_train[col],prefix=col,drop_first=True)\n",
    "    cd_train=pd.concat([temp,cd_train],1)\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    \n",
    "    temp=pd.get_dummies(cd_test[col],prefix=col,drop_first=True)\n",
    "    cd_test=pd.concat([temp,cd_test],1)\n",
    "    cd_test.drop([col],1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = cd_train.drop(['Consumer disputed?','Complaint ID'],1)\n",
    "y = cd_train['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train_test splits on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ld_train, ld_test = train_test_split(cd_train, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x80_train = ld_train.drop(['Consumer disputed?','Complaint ID'],1)\n",
    "y80_train = ld_train['Consumer disputed?']\n",
    "\n",
    "x20_test = ld_test.drop(['Consumer disputed?','Complaint ID'],1)\n",
    "y20_test = ld_test['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Check ROC_AUC_SCORE  {penalty='l1', class_weight=None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_logr1 = LogisticRegression(penalty=\"l1\",class_weight=None,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=2, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr1.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y20_test_pred = np.where(model_logr1.predict(ld_test.drop(['Complaint ID','Consumer disputed?'],1))==1,1,0)\n",
    "y20_test_pred = np.where(model_logr1.predict(x20_test)==1,1,0)\n",
    "temp_df = pd.DataFrame(list(zip(cd_test['Complaint ID'],list(y20_test_pred))), columns=['Complaint ID','Consumer disputed?'])\n",
    "\n",
    "y_test_pred = temp_df['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check ROC_AUC_SCORE  {penalty='l2', class_weight=None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_logrl2 = LogisticRegression(penalty=\"l2\",class_weight=None,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logrl2.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y20_test_pred = np.where(model_logrl2.predict(x20_test)==1,1,0)\n",
    "temp_df = pd.DataFrame(list(zip(cd_test['Complaint ID'],list(y20_test_pred))), columns=['Complaint ID','Consumer disputed?'])\n",
    "\n",
    "y_test_pred = temp_df['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4996866817311203"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check ROC_AUC_SCORE {penalty='l1', class_weight='balanced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_logr2 = LogisticRegression(penalty=\"l1\",class_weight=\"balanced\",random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=2,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr2.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y20_test_pred2 = np.where(model_logr2.predict(ld_test.drop(['Complaint ID','Consumer disputed?'],1))==1,1,0)\n",
    "temp_df2 = pd.DataFrame(list(zip(cd_test['Complaint ID'],list(y20_test_pred2))),\n",
    "                       columns=['Complaint ID','Consumer disputed?'])\n",
    "\n",
    "y_test_pred2 = temp_df2['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5775594371000643"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check ROC_AUC_SCORE  {penalty='l2', class_weight='balanced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_logr3 = LogisticRegression(penalty=\"l2\",class_weight=\"balanced\",random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=2,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr3.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y20_test_pred3 = np.where(model_logr3.predict(ld_test.drop(['Complaint ID','Consumer disputed?'],1))==1,1,0)\n",
    "temp_df3 = pd.DataFrame(list(zip(cd_test['Complaint ID'],list(y20_test_pred3))),\n",
    "                       columns=['Complaint ID','Consumer disputed?'])\n",
    "\n",
    "y_test_pred3 = temp_df3['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52907311874384377"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizing Model continues..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Employ CV procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568003510755\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.56      0.67    249426\n",
      "          1       0.27      0.60      0.37     67315\n",
      "\n",
      "avg / total       0.72      0.57      0.61    316741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = cross_validation.cross_val_predict(model_logr2, x, y, cv=10)\n",
    "print(accuracy_score(y, predicted))\n",
    "print(classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cutoff based predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_score=pd.Series(list(zip(*model_logr2.predict_proba(x80_train)))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0,1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these cutoff , we are going to look at TP,FP,TN,FN values and caluclate KS. Then we'll choose the best cutoff as the one having highest KS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KS_cut=[]\n",
    "for cutoff in cutoffs:\n",
    "    predicted=pd.Series([0]*len(y80_train))\n",
    "    predicted[prob_score>cutoff]=1\n",
    "    df=pd.DataFrame(list(zip(y80_train,predicted)),columns=[\"real\",\"predicted\"])\n",
    "    TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "    FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "    TN=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==0) ])\n",
    "    FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    KS=(TP/P)-(FP/N)\n",
    "    KS_cut.append(KS)\n",
    "\n",
    "cutoff_data=pd.DataFrame(list(zip(cutoffs,KS_cut)),columns=[\"cutoff\",\"KS\"])\n",
    "\n",
    "KS_cutoff=cutoff_data[cutoff_data[\"KS\"]==cutoff_data[\"KS\"].max()][\"cutoff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll see how this model with the cutoff determined here , performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      " \n",
      "  predicted      0      1\n",
      "real                   \n",
      "0          24178  25699\n",
      "1           4349   9123\n"
     ]
    }
   ],
   "source": [
    "# Performance on test data\n",
    "prob_score_test=pd.Series(list(zip(*model_logr2.predict_proba(x20_test)))[1])\n",
    "\n",
    "predicted_test=pd.Series([0]*len(y20_test))\n",
    "predicted_test[prob_score_test > float(KS_cutoff)]=1\n",
    "\n",
    "df_test=pd.DataFrame(list(zip(y20_test,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "print('confusion matrix :\\n \\n ',k)\n",
    "TN=k.iloc[0,0]\n",
    "TP=k.iloc[1,1]\n",
    "FP=k.iloc[0,1]\n",
    "FN=k.iloc[1,0]\n",
    "P=TP+FN\n",
    "N=TN+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52567522770683039"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of test\n",
    "(TP+TN)/(P+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67718230403800472"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity on test\n",
    "TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48475249112817531"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specificity on test\n",
    "TN/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the optimized model on actual x,y and predict y from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=2,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr2.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = np.where(model_logr2.predict(cd_test.drop(['Complaint ID'],1))==1,\"Yes\",\"No\")\n",
    "submission = pd.DataFrame(list(zip(cd_test['Complaint ID'],list(prediction))),\n",
    "                       columns=['Complaint ID','Consumer disputed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_y = submission['Consumer disputed?']\n",
    "actual_y = cd_train['Consumer disputed?']\n",
    "# roc_auc_score(actual_y, pred_y) # This will fail since the probability pairs are one-one between y_actual and y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complaint ID</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675956</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1858795</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32637</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1731374</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Complaint ID Consumer disputed?\n",
       "0        675956                Yes\n",
       "1       1858795                 No\n",
       "2         32637                Yes\n",
       "3       1731374                 No"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission will get you auc score of approx 0.50, slightly less, try to increase the score. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
