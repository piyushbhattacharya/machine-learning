{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datafile_train=r'carvan_train.csv'\n",
    "datafile_test=r'carvan_test.csv'\n",
    "cd_train=pd.read_csv(datafile_train)\n",
    "cd_test=pd.read_csv(datafile_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5822"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10 ...   V77  V78  V79  V80  V81  V82  \\\n",
       "0  33   1   3   2   8   0   5   1   3    7 ...     0    0    0    1    0    0   \n",
       "1  37   1   2   2   8   1   4   1   4    6 ...     0    0    0    1    0    0   \n",
       "2  37   1   2   2   8   0   4   2   4    3 ...     0    0    0    1    0    0   \n",
       "3   9   1   3   3   3   2   3   2   4    5 ...     0    0    0    1    0    0   \n",
       "4  40   1   4   2  10   1   4   1   4    7 ...     0    0    0    1    0    0   \n",
       "\n",
       "   V83  V84  V85  V86  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = cd_train.drop(['V86'],1)\n",
    "y = cd_train['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train_test splits on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ld_train, ld_test = train_test_split(cd_train, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x80_train = ld_train.drop(['V86'],1)\n",
    "y80_train = ld_train['V86']\n",
    "\n",
    "x20_test = ld_test.drop(['V86'],1)\n",
    "y20_test = ld_test['V86']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Check ROC_AUC_SCORE  {penalty='l1', class_weight=None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_logr1 = LogisticRegression(penalty=\"l1\",class_weight=None,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=2, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr1.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y20_test_pred1 = np.where(model_logr1.predict(x20_test)==1,1,0)\n",
    "temp_df1 = pd.DataFrame(list(zip(cd_test['V1'],list(y20_test_pred1))), columns=['V1','V86'])\n",
    "\n",
    "y_test_pred1 = temp_df1['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50574923547400619"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check ROC_AUC_SCORE  {penalty='l2', class_weight=None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_logrl2 = LogisticRegression(penalty=\"l2\",class_weight=None,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logrl2.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y20_test_pred2 = np.where(model_logrl2.predict(x20_test)==1,1,0)\n",
    "temp_df2 = pd.DataFrame(list(zip(cd_test['V1'],list(y20_test_pred2))), columns=['V1','V86'])\n",
    "\n",
    "y_test_pred2 = temp_df2['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50574923547400619"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check ROC_AUC_SCORE {penalty='l1', class_weight='balanced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_logr3 = LogisticRegression(penalty=\"l1\",class_weight=\"balanced\",random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=2,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr3.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y20_test_pred3 = np.where(model_logr3.predict(x20_test)==1,1,0)\n",
    "temp_df3 = pd.DataFrame(list(zip(cd_test['V1'],list(y20_test_pred3))), columns=['V1','V86'])\n",
    "\n",
    "y_test_pred3 = temp_df3['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67596330275229366"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check ROC_AUC_SCORE  {penalty='l2', class_weight='balanced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_logr4 = LogisticRegression(penalty=\"l2\",class_weight=\"balanced\",random_state=2, solver=\"newton-cg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=2,\n",
       "          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr4.fit(x80_train, y80_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y20_test_pred4 = np.where(model_logr4.predict(x20_test)==1,1,0)\n",
    "temp_df4 = pd.DataFrame(list(zip(cd_test['V1'],list(y20_test_pred4))), columns=['V1','V86'])\n",
    "\n",
    "y_test_pred4 = temp_df4['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67688073394495418"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y20_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_score=pd.Series(list(zip(*model_logr4.predict_proba(x80_train)))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate optimum FBeta score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Calculate cutoffs and best KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0,1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these cutoff , we are going to look at TP,FP,TN,FN values and calculate KS. Then we'll chose the best cutoff as the one having highest KS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KS_cut=[]\n",
    "for cutoff in cutoffs:\n",
    "    predicted = pd.Series([0]*len(y80_train))\n",
    "    predicted[prob_score > cutoff] = 1\n",
    "    df = pd.DataFrame(list(zip(y80_train,predicted)),columns=[\"real\",\"predicted\"])\n",
    "    TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "    FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "    TN=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==0) ])\n",
    "    FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    KS=(TP/P)-(FP/N)\n",
    "    KS_cut.append(KS)\n",
    "\n",
    "cutoff_data=pd.DataFrame(list(zip(cutoffs,KS_cut)),columns=[\"cutoff\",\"KS\"])\n",
    "\n",
    "KS_cutoff=cutoff_data[cutoff_data[\"KS\"]==cutoff_data[\"KS\"].max()][\"cutoff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll see how this model with the cutoff determined here , performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      " \n",
      "  predicted    0    1\n",
      "real               \n",
      "0          833  257\n",
      "1           34   41\n"
     ]
    }
   ],
   "source": [
    "# Performance on test data\n",
    "prob_score_test=pd.Series(list(zip(*model_logr4.predict_proba(x20_test)))[1])\n",
    "\n",
    "predicted_test=pd.Series([0]*len(y20_test))\n",
    "predicted_test[prob_score_test>float(KS_cutoff)]=1\n",
    "\n",
    "df_test=pd.DataFrame(list(zip(y20_test,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "print('confusion matrix :\\n \\n ',k)\n",
    "TN=k.iloc[0,0]\n",
    "TP=k.iloc[1,1]\n",
    "FP=k.iloc[0,1]\n",
    "FN=k.iloc[1,0]\n",
    "P=TP+FN\n",
    "N=TN+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.750214592275\n",
      "sensitivity :  0.546666666667\n",
      "specificity :  0.764220183486\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of test\n",
    "accuracy = (TP+TN)/(P+N)\n",
    "# Sensitivity on test\n",
    "sensitivity = TP/P\n",
    "#Specificity on test\n",
    "specificity = TN/N\n",
    "\n",
    "print(\"accuracy : \", accuracy)\n",
    "print(\"sensitivity : \", sensitivity)\n",
    "print(\"specificity : \", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we see how cutoff determined by F_beta score performs on test data for beta values : 0.5,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0.010,0.99,100)\n",
    "def Fbeta_perf(beta,cutoffs,y80_train,prob_score):\n",
    "    FB_cut=[]\n",
    "    for cutoff in cutoffs:\n",
    "        predicted=pd.Series([0]*len(y80_train))\n",
    "        predicted[prob_score>cutoff]=1\n",
    "        df=pd.DataFrame(list(zip(y80_train,predicted)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "        TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "        FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "        FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "        P=TP+FN\n",
    "        \n",
    "        \n",
    "        Precision=TP/(TP+FP)\n",
    "        Recall=TP/P\n",
    "        FB=(1+beta**2)*Precision*Recall/((beta**2)*Precision+Recall)\n",
    "        FB_cut.append(FB)\n",
    "\n",
    "    cutoff_data=pd.DataFrame(list(zip(cutoffs,FB_cut)),columns=[\"cutoff\",\"FB\"])\n",
    "\n",
    "    FB_cutoff=cutoff_data[cutoff_data[\"FB\"]==cutoff_data[\"FB\"].max()][\"cutoff\"]\n",
    "\n",
    "    prob_score_test=pd.Series(list(zip(*model_logr4.predict_proba(x20_test)))[1])\n",
    "\n",
    "    predicted_test=pd.Series([0]*len(y20_test))\n",
    "    predicted_test[prob_score_test>float(FB_cutoff)]=1\n",
    "\n",
    "    df_test=pd.DataFrame(list(zip(y20_test,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "    k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "#     print('confusion matrix :\\n \\n ',k)\n",
    "    TN=k.iloc[0,0]\n",
    "    TP=k.iloc[1,1]\n",
    "    FP=k.iloc[0,1]\n",
    "    FN=k.iloc[1,0]\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    print('For beta :',beta)\n",
    "    print('Accuracy is :',(TP+TN)/(P+N))\n",
    "    print('Sensitivity is :',(TP/P))\n",
    "    print('Specificity is :',(TN/N))\n",
    "    print('\\n \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For beta : 0.5\n",
      "Accuracy is : 0.915021459227\n",
      "Sensitivity is : 0.226666666667\n",
      "Specificity is : 0.962385321101\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 1\n",
      "Accuracy is : 0.843776824034\n",
      "Sensitivity is : 0.426666666667\n",
      "Specificity is : 0.87247706422\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 1.5\n",
      "Accuracy is : 0.781115879828\n",
      "Sensitivity is : 0.506666666667\n",
      "Specificity is : 0.8\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 2\n",
      "Accuracy is : 0.763090128755\n",
      "Sensitivity is : 0.533333333333\n",
      "Specificity is : 0.778899082569\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 2.5\n",
      "Accuracy is : 0.763090128755\n",
      "Sensitivity is : 0.533333333333\n",
      "Specificity is : 0.778899082569\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "For beta : 3.0\n",
      "Accuracy is : 0.634334763948\n",
      "Sensitivity is : 0.693333333333\n",
      "Specificity is : 0.630275229358\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Fbeta_perf(0.5,cutoffs,y80_train,prob_score)\n",
    "Fbeta_perf(1,cutoffs,y80_train,prob_score)\n",
    "Fbeta_perf(1.5,cutoffs,y80_train,prob_score)\n",
    "Fbeta_perf(2,cutoffs,y80_train,prob_score)\n",
    "Fbeta_perf(2.5,cutoffs,y80_train,prob_score)\n",
    "Fbeta_perf(3.0,cutoffs,y80_train,prob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Calculate FBeta score on original optimal model {model_logr4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Beta :  1.0\n",
      "fscore_ma :  0.220689655172\n",
      "fscore_mi :  0.220689655172\n",
      "fscore_w :  0.220689655172\n",
      "fscore_n :  [ 0.82110818  0.22068966]\n",
      "\n",
      "\n",
      "Beta :  1.5\n",
      "fscore_ma :  0.295035460993\n",
      "fscore_mi :  0.295035460993\n",
      "fscore_w :  0.295035460993\n",
      "fscore_n :  [ 0.77620875  0.29503546]\n",
      "\n",
      "\n",
      "Beta :  2.0\n",
      "fscore_ma :  0.363636363636\n",
      "fscore_mi :  0.363636363636\n",
      "fscore_w :  0.363636363636\n",
      "fscore_n :  [ 0.75314618  0.36363636]\n",
      "\n",
      "\n",
      "Beta :  2.5\n",
      "fscore_ma :  0.419909502262\n",
      "fscore_mi :  0.419909502262\n",
      "fscore_w :  0.419909502262\n",
      "fscore_n :  [ 0.74046603  0.4199095 ]\n",
      "\n",
      "\n",
      "Beta :  3.0\n",
      "fscore_ma :  0.463768115942\n",
      "fscore_mi :  0.463768115942\n",
      "fscore_w :  0.463768115942\n",
      "fscore_n :  [ 0.73292511  0.46376812]\n"
     ]
    }
   ],
   "source": [
    "betas = np.linspace(1,3,num=5)\n",
    "for ta in betas:\n",
    "    print('\\n')\n",
    "    print('Beta : ', ta)\n",
    "    fscorema = fbeta_score(y20_test, y_test_pred4, average='macro', beta=ta)\n",
    "    print('fscore_ma : ' ,fscorema)\n",
    "    fscoremi = fbeta_score(y20_test, y_test_pred4, average='micro', beta=ta)\n",
    "    print('fscore_mi : ' ,fscoremi)\n",
    "    fscorew = fbeta_score(y20_test, y_test_pred4, average='weighted', beta=ta)\n",
    "    print('fscore_w : ' ,fscorew)\n",
    "    fscoren = fbeta_score(y20_test, y_test_pred4, average=None, beta=ta)\n",
    "    print('fscore_n : ' ,fscoren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscorema :  0.419909502262\n",
      "fscoremi :  0.419909502262\n",
      "fscorew :  0.419909502262\n",
      "fscoren :  [ 0.74046603  0.4199095 ]\n"
     ]
    }
   ],
   "source": [
    "print('fscorema : ' ,fscorema)\n",
    "print('fscoremi : ' ,fscoremi)\n",
    "print('fscorew : ' ,fscorew)\n",
    "print('fscoren : ' ,fscoren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the optimized model on actual x,y and predict y from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_logr4.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = np.where(model_logr4.predict(cd_test)==1,\"Yes\",\"No\")\n",
    "submission = pd.DataFrame(list(zip(cd_test['V1'],list(prediction))),\n",
    "                       columns=['V1','V86'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_y = submission['V86']\n",
    "actual_y = cd_train['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V86\n",
       "0  33   No\n",
       "1   6  Yes\n",
       "2  39   No\n",
       "3   9  Yes"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_carvan.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission will get you auc score of approx 0.50, slightly less than whats required for passing the course. You'll have to make changes "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
